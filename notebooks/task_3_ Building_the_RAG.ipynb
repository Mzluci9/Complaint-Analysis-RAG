{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b5c7d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from accelerate) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.5.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83701722",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "import logging\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab316502",
   "metadata": {},
   "source": [
    "# Load Chunked Data and FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862d9387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 10:56:57,850 - INFO - Loaded chunked dataset with shape: (763160, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['complaint_id', 'product', 'chunk_idx', 'chunk_text', 'chunk_length']\n",
      "\n",
      "Sample Chunks (first 5):\n",
      "   complaint_id          product  chunk_idx  \\\n",
      "0      14069121      Credit Card          0   \n",
      "1      14061897  Savings Account          0   \n",
      "2      14047085      Credit Card          0   \n",
      "3      14040217      Credit Card          0   \n",
      "4      14040217      Credit Card          1   \n",
      "\n",
      "                                          chunk_text  \n",
      "0  a card was opened under my name by a fraudster...  \n",
      "1  i made the mistake of using my wellsfargo debi...  \n",
      "2  i have a secured credit card with citibank whi...  \n",
      "3  i have a citi rewards cards the credit balance...  \n",
      "4  prior to the notification about reaching my li...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 10:57:00,454 - INFO - FAISS index size: 763160\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Load chunked data\n",
    "data_path = r'C:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\data\\chunked_complaints.csv'\n",
    "try:\n",
    "    df_chunks = pd.read_csv(data_path)\n",
    "    logging.info(f\"Loaded chunked dataset with shape: {df_chunks.shape}\")\n",
    "    print(\"Columns:\", df_chunks.columns.tolist())\n",
    "    print(\"\\nSample Chunks (first 5):\")\n",
    "    print(df_chunks[['complaint_id', 'product', 'chunk_idx', 'chunk_text']].head())\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load chunked dataset: {e}\")\n",
    "    raise\n",
    "\n",
    "# Load FAISS index\n",
    "index_path = r'C:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\data\\complaint_index.faiss'\n",
    "try:\n",
    "    index = faiss.read_index(index_path)\n",
    "    logging.info(f\"FAISS index size: {index.ntotal}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to load FAISS index: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7edaf",
   "metadata": {},
   "source": [
    "# Implement the Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7653525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 10:58:09,664 - INFO - Use pytorch device_name: cpu\n",
      "2025-07-06 10:58:09,665 - INFO - Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Why are people unhappy with BNPL?\n",
      "Retrieved Chunks:\n",
      "Chunk 1 (Product: Buy Now, Pay Later (BNPL), Distance: 0.9367):\n",
      "practices of bnpl companies reporting only negative data creates an incomplete and potentially damaging picture of a consumer s creditworthiness it is my understanding that the cfpb has been looking into the bnpl sector and the unfair practices that are being used difficulty accessing assistance during financial hardship furthermore affirm does not provide easily accessible avenues for customers to seek assistance during periods of financial hardship navigating their customer service channels to request payment arrangements or other forms of support is unnecessarily difficult and frustrating this lack of transparency and accessibility exacerbates the negative impact of late payments particularly during unforeseen financial challenges i have attempted to contact them and have received no assistance\n",
      "Chunk 2 (Product: Credit Card, Distance: 1.0844):\n",
      "to deceive consumers boa fails to treat customers as people but is too big to fail but boa continues to fail because it has no incentive to change perhaps boa should fleece third world customers as it would be easier since english is poor\n",
      "Chunk 3 (Product: Savings Account, Distance: 1.1104):\n",
      "there inability to handle fruad so they take it out on there customers with ridiculous non objective systems that handle sensitive incidents like this its how they save money they need a well funded department with hundreds of real people handling situations like this but instead they choose cost effective measures like a computer system instead real people this is because there share holders need to be stuffed with enough money to keep them investing never mind the small business man who is the very reason they exist in the first place this is a flawed and sick system that need sweeping change\n",
      "Chunk 4 (Product: Money Transfers, Distance: 1.1338):\n",
      "have been a boa customer for upwards of years and i am appalled at their lack of concern\n",
      "Chunk 5 (Product: Money Transfers, Distance: 1.1395):\n",
      "because they are incompetent\n",
      "\n",
      "Query: What are common issues with Credit Card fraud?\n",
      "Retrieved Chunks:\n",
      "Chunk 1 (Product: Credit Card, Distance: 0.6186):\n",
      "fraudulent cards even though they are aware there are issues\n",
      "Chunk 2 (Product: Credit Card, Distance: 0.6729):\n",
      "there as well all because of a flawed process by the credit card company for which i firmly believe they are liable\n",
      "Chunk 3 (Product: Credit Card, Distance: 0.6923):\n",
      "credit card keeps getting stolen and charged with fraudulent transactions\n",
      "Chunk 4 (Product: Credit Card, Distance: 0.7108):\n",
      "gone really bad with the company especially on these fraud detection and prevention i had a couple instances last year and every time they would have to send me a new set of cards and it really disrupted my payment setup in many places\n",
      "Chunk 5 (Product: Money Transfers, Distance: 0.7142):\n",
      "my debit card credit card information on as well as poor security measures is what caused the fraud to occur\n",
      "\n",
      "Query: Why do Savings Account complaints happen?\n",
      "Retrieved Chunks:\n",
      "Chunk 1 (Product: Savings Account, Distance: 0.5227):\n",
      "m t since i opened my first savings account this was not investigated to my satisfaction and i am not letting this go if submitting this complaint does not bring me a satisfactory response and resolution they will not only lose a valued costumer of upwards of a decade i also plan to take legal action i also have no problem publishing my story to the local news and media outlets as i am sure i am not the only one who has experienced this\n",
      "Chunk 2 (Product: Savings Account, Distance: 0.6492):\n",
      "and with a negative balance plus reported me to the i m furious so why did they keep my savings account open this is totally ridiculous i m reporting them so other consumers can be aware and they must fix this wrong\n",
      "Chunk 3 (Product: Money Transfers, Distance: 0.6659):\n",
      "savings account it has been devastating\n",
      "Chunk 4 (Product: Savings Account, Distance: 0.6873):\n",
      "savings account\n",
      "Chunk 5 (Product: Savings Account, Distance: 0.6873):\n",
      "savings account\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def retrieve_chunks(query, index, df_chunks, model, top_k=5):\n",
    "    try:\n",
    "        # Encode query\n",
    "        query_embedding = model.encode([query], show_progress_bar=False)\n",
    "        # Search FAISS index\n",
    "        distances, indices = index.search(np.array(query_embedding, dtype=np.float32), top_k)\n",
    "        # Get corresponding chunks\n",
    "        retrieved_chunks = df_chunks.iloc[indices[0]][['complaint_id', 'product', 'chunk_idx', 'chunk_text']].to_dict('records')\n",
    "        return retrieved_chunks, distances[0]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error retrieving chunks for query '{query}': {e}\")\n",
    "        return [], []\n",
    "\n",
    "# Test retriever\n",
    "sample_queries = [\n",
    "    \"Why are people unhappy with BNPL?\",\n",
    "    \"What are common issues with Credit Card fraud?\",\n",
    "    \"Why do Savings Account complaints happen?\"\n",
    "]\n",
    "for query in sample_queries:\n",
    "    chunks, distances = retrieve_chunks(query, index, df_chunks, model)\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(\"Retrieved Chunks:\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i+1} (Product: {chunk['product']}, Distance: {distances[i]:.4f}):\")\n",
    "        print(chunk['chunk_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9365f71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (0.46.1)\n",
      "Requirement already satisfied: torch<3,>=2.2 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from bitsandbytes) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from bitsandbytes) (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (2025.5.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\10 acadamy projects\\new folder (6)\\complaint-analysis-rag\\.venv\\lib\\site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd6d73f",
   "metadata": {},
   "source": [
    "# Set Up the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e96d7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "quant_type must be nf4 on CPU, got fp4",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mHuggingFaceH4/zephyr-7b-beta\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mllm_int8_enable_fp32_cpu_offload\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m llm = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Example inputs\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:311\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    313\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4833\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4823\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4824\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4826\u001b[39m     (\n\u001b[32m   4827\u001b[39m         model,\n\u001b[32m   4828\u001b[39m         missing_keys,\n\u001b[32m   4829\u001b[39m         unexpected_keys,\n\u001b[32m   4830\u001b[39m         mismatched_keys,\n\u001b[32m   4831\u001b[39m         offload_index,\n\u001b[32m   4832\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4833\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4834\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4835\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4836\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4837\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4838\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4839\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4840\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4841\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4842\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4845\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4849\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4851\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4852\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:5296\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   5293\u001b[39m         args_list = logging.tqdm(args_list, desc=\u001b[33m\"\u001b[39m\u001b[33mLoading checkpoint shards\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   5295\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[32m-> \u001b[39m\u001b[32m5296\u001b[39m         _error_msgs, disk_offload_index, cpu_offload_index = \u001b[43mload_shard_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5297\u001b[39m         error_msgs += _error_msgs\n\u001b[32m   5299\u001b[39m \u001b[38;5;66;03m# Adjust offloaded weights name and save if needed\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:933\u001b[39m, in \u001b[36mload_shard_file\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;66;03m# Skip it with fsdp on ranks other than 0\u001b[39;00m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_fsdp_enabled() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local_dist_rank_0() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_quantized):\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m     disk_offload_index, cpu_offload_index = \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreverse_key_renaming_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisk_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_offload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_offloaded_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m        \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m error_msgs, disk_offload_index, cpu_offload_index\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:848\u001b[39m, in \u001b[36m_load_state_dict_into_meta_model\u001b[39m\u001b[34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[39m\n\u001b[32m    845\u001b[39m     _load_parameter_into_model(model, param_name, param.to(param_device))\n\u001b[32m    847\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m     \u001b[43mhf_quantizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_quantized_param\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munexpected_keys\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    851\u001b[39m     \u001b[38;5;66;03m# For quantized modules with FSDP/DeepSpeed Stage 3, we need to quantize the parameter on the GPU\u001b[39;00m\n\u001b[32m    852\u001b[39m     \u001b[38;5;66;03m# and then cast it to CPU to avoid excessive memory usage on each GPU\u001b[39;00m\n\u001b[32m    853\u001b[39m     \u001b[38;5;66;03m# in comparison to the sharded model across GPUs.\u001b[39;00m\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_fsdp_enabled() \u001b[38;5;129;01mor\u001b[39;00m is_deepspeed_zero3_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:250\u001b[39m, in \u001b[36mBnb4BitHfQuantizer.create_quantized_param\u001b[39m\u001b[34m(self, model, param_value, param_name, target_device, state_dict, unexpected_keys)\u001b[39m\n\u001b[32m    247\u001b[39m         new_value = new_value.T\n\u001b[32m    249\u001b[39m     kwargs = old_value.\u001b[34m__dict__\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     new_value = \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mParams4bit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m module._parameters[tensor_name] = new_value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:336\u001b[39m, in \u001b[36mParams4bit.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    333\u001b[39m device, dtype, non_blocking, convert_to_format = torch._C._nn._parse_to(*args, **kwargs)\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m device.type != \u001b[33m\"\u001b[39m\u001b[33mmeta\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.bnb_quantized:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_quantize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.quant_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\bitsandbytes\\nn\\modules.py:295\u001b[39m, in \u001b[36mParams4bit._quantize\u001b[39m\u001b[34m(self, device)\u001b[39m\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_quantize\u001b[39m(\u001b[38;5;28mself\u001b[39m, device):\n\u001b[32m    294\u001b[39m     w = \u001b[38;5;28mself\u001b[39m.data.contiguous().to(device)\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     w_4bit, quant_state = \u001b[43mbnb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantize_4bit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompress_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = w_4bit\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m.quant_state = quant_state\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\bitsandbytes\\functional.py:1008\u001b[39m, in \u001b[36mquantize_4bit\u001b[39m\u001b[34m(A, absmax, out, blocksize, compress_statistics, quant_type, quant_storage)\u001b[39m\n\u001b[32m    983\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Quantize tensor A in blocks of 4-bit values.\u001b[39;00m\n\u001b[32m    984\u001b[39m \n\u001b[32m    985\u001b[39m \u001b[33;03mQuantizes tensor A by dividing it into blocks which are independently quantized.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m \u001b[33;03m    - [`QuantState`]: The state object used to undo the quantization.\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1006\u001b[39m input_shape = A.shape\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m _out, _absmax = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbitsandbytes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantize_4bit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquant_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m code = get_4bit_type(quant_type, device=A.device)\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compress_statistics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\torch\\_ops.py:756\u001b[39m, in \u001b[36mOpOverload.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\torch\\_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    836\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    840\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\torch\\library.py:719\u001b[39m, in \u001b[36m_impl.<locals>.register_.<locals>.func_no_dynamo\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m \u001b[38;5;129m@torch\u001b[39m._disable_dynamo\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_no_dynamo\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\bitsandbytes\\backends\\cpu\\ops.py:98\u001b[39m, in \u001b[36m_\u001b[39m\u001b[34m(A, blocksize, quant_type, quant_storage)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;129m@register_kernel\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mbitsandbytes::quantize_4bit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_\u001b[39m(\n\u001b[32m     95\u001b[39m     A: torch.Tensor, blocksize: \u001b[38;5;28mint\u001b[39m, quant_type: \u001b[38;5;28mstr\u001b[39m, quant_storage: torch.dtype\n\u001b[32m     96\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor, torch.Tensor]:\n\u001b[32m     97\u001b[39m     torch._check_is_size(blocksize)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquant_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnf4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquant_type must be nf4 on CPU, got \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquant_type\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     torch._check(\n\u001b[32m    100\u001b[39m         A.dtype \u001b[38;5;129;01min\u001b[39;00m [torch.bfloat16, torch.float16, torch.float32],\n\u001b[32m    101\u001b[39m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBlockwise 4bit quantization only supports 16/32-bit floats, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m     )\n\u001b[32m    104\u001b[39m     n = A.numel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\torch\\__init__.py:1660\u001b[39m, in \u001b[36m_check\u001b[39m\u001b[34m(cond, message)\u001b[39m\n\u001b[32m   1645\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_check\u001b[39m(cond, message=\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[32m   1646\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Throws error containing an optional message if the specified condition\u001b[39;00m\n\u001b[32m   1647\u001b[39m \u001b[33;03m    is False.\u001b[39;00m\n\u001b[32m   1648\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1658\u001b[39m \u001b[33;03m            message. Default: ``None``\u001b[39;00m\n\u001b[32m   1659\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1660\u001b[39m     \u001b[43m_check_with\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;167;43;01mRuntimeError\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\10 Acadamy PRojects\\New folder (6)\\Complaint-Analysis-RAG\\.venv\\Lib\\site-packages\\torch\\__init__.py:1642\u001b[39m, in \u001b[36m_check_with\u001b[39m\u001b[34m(error_type, cond, message)\u001b[39m\n\u001b[32m   1638\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mmessage must be a callable\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1640\u001b[39m     message_evaluated = \u001b[38;5;28mstr\u001b[39m(message())\n\u001b[32m-> \u001b[39m\u001b[32m1642\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m error_type(message_evaluated)\n",
      "\u001b[31mRuntimeError\u001b[39m: quant_type must be nf4 on CPU, got fp4"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_4bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True,\n",
    ")\n",
    "\n",
    "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "# Example inputs\n",
    "system_prompt = \"You are a helpful financial assistant.\"\n",
    "user_question = \"What are the main risks in microloans?\"\n",
    "retrieved_chunks = [\n",
    "    \"Microloans often face high default rates due to limited borrower credit history.\",\n",
    "    \"Operational costs can be disproportionately high relative to loan size.\"\n",
    "]\n",
    "\n",
    "# Combine them\n",
    "full_prompt = f\"<|system|>\\n{system_prompt}\\n<|user|>\\n{user_question}\\n<|retrieved|>\\n\" + \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "# Generate\n",
    "response = llm(full_prompt, max_new_tokens=200, do_sample=True, temperature=0.7)\n",
    "\n",
    "# Extract & print output\n",
    "print(response[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe29fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8a327",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
